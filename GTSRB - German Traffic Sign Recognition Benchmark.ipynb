{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,Activation\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "cur_path = r'C:\\Users\\chris\\Documents\\Git_repo\\GTSRB_TF\\GTSRB---German-Traffic-Sign-Recognition\\gtsrb-german-traffic-sign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    " \n",
    "\n",
    "#Retrieving the images and their labels \n",
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'train',str(i))\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "    \n",
    "            #data.append(image)\n",
    "            #labels.append(i)\n",
    "            data.append([image,i]) #appending all value together \n",
    "        except:\n",
    "            print(\"Error loading image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39209\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for features,label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Converting lists into numpy arrays\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array(x).reshape(-1, 30, 30, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images is: (31367, 30, 30, 3)\n",
      "Shape of labels is: (31367,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train images is:\", X_train.shape)\n",
    "print(\"Shape of labels is:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\Documents\\Git_repo\\GTSRB_TF\\GTSRB---German-Traffic-Sign-Recognition\\.conda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(30, 30, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(43))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\Documents\\Git_repo\\GTSRB_TF\\GTSRB---German-Traffic-Sign-Recognition\\.conda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 26ms/step - accuracy: 0.1657 - loss: 3.0908 - val_accuracy: 0.5416 - val_loss: 1.3512\n",
      "Epoch 2/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - accuracy: 0.4828 - loss: 1.5750 - val_accuracy: 0.7456 - val_loss: 0.7753\n",
      "Epoch 3/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.6280 - loss: 1.0794 - val_accuracy: 0.8407 - val_loss: 0.4823\n",
      "Epoch 4/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.7433 - loss: 0.7478 - val_accuracy: 0.9220 - val_loss: 0.2739\n",
      "Epoch 5/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.8212 - loss: 0.5344 - val_accuracy: 0.9607 - val_loss: 0.1587\n",
      "Epoch 6/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.8651 - loss: 0.4073 - val_accuracy: 0.9726 - val_loss: 0.0990\n",
      "Epoch 7/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8952 - loss: 0.3161 - val_accuracy: 0.9802 - val_loss: 0.0844\n",
      "Epoch 8/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.9176 - loss: 0.2582 - val_accuracy: 0.9816 - val_loss: 0.0612\n",
      "Epoch 9/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - accuracy: 0.9300 - loss: 0.2214 - val_accuracy: 0.9867 - val_loss: 0.0517\n",
      "Epoch 10/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.9408 - loss: 0.1857 - val_accuracy: 0.9885 - val_loss: 0.0450\n",
      "Epoch 11/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9485 - loss: 0.1555 - val_accuracy: 0.9880 - val_loss: 0.0412\n",
      "Epoch 12/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - accuracy: 0.9551 - loss: 0.1419 - val_accuracy: 0.9907 - val_loss: 0.0390\n",
      "Epoch 13/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9640 - loss: 0.1191 - val_accuracy: 0.9911 - val_loss: 0.0315\n",
      "Epoch 14/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24ms/step - accuracy: 0.9630 - loss: 0.1187 - val_accuracy: 0.9939 - val_loss: 0.0281\n",
      "Epoch 15/15\n",
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9681 - loss: 0.1005 - val_accuracy: 0.9946 - val_loss: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "model.fit(aug.flow(X_train, y_train, batch_size=32), epochs=15, validation_data=(X_val, y_val))\n",
    "\n",
    "model.save('my_model2.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "0.920110847189232\n"
     ]
    }
   ],
   "source": [
    "#testing accuracy on test dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = pd.read_csv('gtsrb-german-traffic-sign/Test.csv')\n",
    "\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = y_test[\"Path\"].values\n",
    "\n",
    "data=[]\n",
    "\n",
    "for img in imgs:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    data.append(np.array(image))\n",
    "\n",
    "X_test=np.array(data)\n",
    "\n",
    "#pred = model.predict_classes(X_test)  \n",
    "\n",
    "pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "#Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are testing our model on our saved model also we can test on our 15 epoch data result we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\chris\\Documents\\Git_repo\\GTSRB_TF\\GTSRB---German-Traffic-Sign-Recognition\\Test\\12614.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Speed limit (20km/h)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "traffic_signs = {\n",
    "    0: 'Speed limit (20km/h)',\n",
    "    1: 'Speed limit (30km/h)',\n",
    "    2: 'Speed limit (50km/h)',\n",
    "    3: 'Speed limit (60km/h)',\n",
    "    4: 'Speed limit (70km/h)',\n",
    "    5: 'Speed limit (80km/h)',\n",
    "    6: 'End of speed limit (80km/h)',\n",
    "    7: 'Speed limit (100km/h)',\n",
    "    8: 'Speed limit (120km/h)',\n",
    "    9: 'No passing',\n",
    "    10: 'No passing vehicles over 3.5 tons',\n",
    "    11: 'Right-of-way at intersection',\n",
    "    12: 'Priority road',\n",
    "    13: 'Yield',\n",
    "    14: 'Stop',\n",
    "    15: 'No vehicles',\n",
    "    16: 'Vehicles over 3.5 tons prohibited',\n",
    "    17: 'No entry',\n",
    "    18: 'General caution',\n",
    "    19: 'Dangerous curve left',\n",
    "    20: 'Dangerous curve right',\n",
    "    21: 'Double curve',\n",
    "    22: 'Bumpy road',\n",
    "    23: 'Slippery road',\n",
    "    24: 'Road narrows on the right',\n",
    "    25: 'Road work',\n",
    "    26: 'Traffic signals',\n",
    "    27: 'Pedestrians',\n",
    "    28: 'Children crossing',\n",
    "    29: 'Bicycles crossing',\n",
    "    30: 'Beware of ice/snow',\n",
    "    31: 'Wild animals crossing',\n",
    "    32: 'End speed + passing limits',\n",
    "    33: 'Turn right ahead',\n",
    "    34: 'Turn left ahead',\n",
    "    35: 'Ahead only',\n",
    "    36: 'Go straight or right',\n",
    "    37: 'Go straight or left',\n",
    "    38: 'Keep right',\n",
    "    39: 'Keep left',\n",
    "    40: 'Roundabout mandatory',\n",
    "    41: 'End of no passing',\n",
    "    42: 'End no passing vehicles > 3.5 tons'\n",
    "}\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = load_img(path, target_size=(30, 30))\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "# Predict the label for the image\n",
    "classes = np.argmax(model.predict(images, batch_size=32), axis=-1)\n",
    "\n",
    "# Print the traffic sign description\n",
    "print(traffic_signs.get(classes[0], \"Unknown sign\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
